#!/bin/bash
###### Job name ######
#PBS -N SPARX
###### Output files ######
#PBS -e SPARX.err
#PBS -o SPARX.log
###### Queue name #######
#PBS -q medium
###### Number of nodes and cores ######
#PBS -l nodes=8:ppn=12
###### Sends mail to yourself when the job begins and ends ######
#PBS -M ithsieh@asiaa.sinica.edu.tw
#PBS -m be
###### Specific the shell types ######
#PBS -S /bin/bash

PBS_O_WORKDIR=/tiara/home/ithsieh/sparx/unit_tests/tmp
mkdir -p $PBS_O_WORKDIR

###### Enter this job's working directory ######
cd $PBS_O_WORKDIR

###### Load modules to setup environment ######
source ~/.load_sparx_module


###### Run parallel jobs ######

if [ -n "$PBS_NODEFILE" ]; then
  if [ -f $PBS_NODEFILE ]; then
    awk '!x[$0]++' $PBS_NODEFILE > MPIHOST
    sed -e 's/$/ slots=1/' -i MPIHOST
    NPROCS=`wc -l < MPIHOST`
  fi
fi

rm -rf pops* history.log

CLUSTERNAME=${HOSTNAME:0:2}
sparx_version=`which sparx-$CLUSTERNAME`

$OPENMPI_HOME/bin/mpirun -v -machinefile MPIHOST -np $NPROCS \
$sparx_version --parallel run task_amc \
source=../storage/sph2d_model/model_env_disk \
out=pops \
molec='co_21lev' \
trace='True' \
lte='True' \
tolerance=5e-3 \
snr=20 \
raniter=2 \
fixiter=2 \
| tee history.log

rm -rf MPIHOST
